{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embr tensor([[[-14.8289,  -8.2562,  54.6304,  ...,   8.4305,  -3.6507, -27.6918],\n",
      "         [-10.6098,  -9.9717,  -2.4429,  ...,   8.3850,  -4.9843,  -6.0591],\n",
      "         [ -1.2095,  22.6689,   5.8902,  ...,  18.8349,   0.3589,  11.6905],\n",
      "         [ 38.0961, -13.7467,  36.3315,  ...,  11.5945, -25.4663,  -5.4805]],\n",
      "\n",
      "        [[-10.6098,  -9.9717,  -2.4429,  ...,   8.3850,  -4.9843,  -6.0591],\n",
      "         [-10.6098,  -9.9717,  -2.4429,  ...,   8.3850,  -4.9843,  -6.0591],\n",
      "         [ -1.2095,  22.6689,   5.8902,  ...,  18.8349,   0.3589,  11.6905],\n",
      "         [ 38.0961, -13.7467,  36.3315,  ...,  11.5945, -25.4663,  -5.4805]]],\n",
      "       grad_fn=<MulBackward0>)\n",
      "embrshape torch.Size([2, 4, 512])\n"
     ]
    }
   ],
   "source": [
    "class Embeddings(nn.Module):\n",
    "\n",
    "    def __init__(self,d_model,vocab):\n",
    "        #d_model:dimension of embedding \n",
    "        #vocab:size of wordlist\n",
    "        super(Embeddings,self).__init__()\n",
    "        self.lut =nn.Embedding(vocab,d_model)\n",
    "        self.d_model =d_model\n",
    "    def forward(self,x):\n",
    "        return self.lut(x)*math.sqrt(self.d_model)\n",
    "    \n",
    "d_model =512\n",
    "vocab = 1000\n",
    "x=torch.LongTensor([[1,2,3,4],[2,2,3,4]])\n",
    "emb =Embeddings(d_model,vocab)\n",
    "emb_rslt=emb(x)\n",
    "print(\"embr\",emb_rslt)\n",
    "print(\"embrshape\",emb_rslt.shape)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 1.8997,  0.6557, -0.1424],\n",
      "         [-0.0872,  0.1228, -0.7261],\n",
      "         [ 0.4782,  0.0221, -1.3902],\n",
      "         [ 0.5069,  0.9979,  0.0901]],\n",
      "\n",
      "        [[-0.0872,  0.1228, -0.7261],\n",
      "         [ 1.5800,  0.5353,  0.6007],\n",
      "         [ 0.4782,  0.0221, -1.3902],\n",
      "         [ 0.1910, -1.2970, -0.9452]]], grad_fn=<EmbeddingBackward0>)\n"
     ]
    }
   ],
   "source": [
    "#nn.Embedding(vocab,d_model)\n",
    "#integer in[0,vocab-1]->vector in R^d_model(randomly)\n",
    "#integer in tensor lut place by place\n",
    "embedding = nn.Embedding(10,3)\n",
    "input = torch.LongTensor([[1,2,4,5],[2,3,4,9]])\n",
    "print(embedding(input))\n",
    "#10:max integer0-9\n",
    "#3:each ->3d\n",
    "#[[1,2,4,5],[2,3,4,9]]\n",
    "#  v\n",
    "#[ 1.8997,  0.6557, -0.1424]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0000,  0.0000,  0.0000],\n",
      "        [ 1.6208,  0.2372, -1.3009]], grad_fn=<EmbeddingBackward0>)\n"
     ]
    }
   ],
   "source": [
    "embedding = nn.Embedding(10,3,padding_idx=1)\n",
    "input=torch.LongTensor([1,0])\n",
    "print(embedding(input))\n",
    "#[1,0]\n",
    "# V\n",
    "#[ 0.0000,  0.0000,  0.0000]\n",
    "#padding_idx->0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Position Encoding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ -0.0000,  -8.0624,  60.7004,  ...,  10.4784,  -4.0564, -29.6576],\n",
      "         [-10.8537, -10.4793,  -2.7143,  ...,  10.4278,  -5.5381,  -5.6212],\n",
      "         [ -0.3336,   0.0000,   6.5446,  ...,  22.0388,   0.0000,  14.1006],\n",
      "         [ 42.4858, -16.3742,  40.3683,  ...,   0.0000, -28.2959,  -4.9783]],\n",
      "\n",
      "        [[-11.7887,  -9.9685,  -2.7143,  ...,  10.4278,  -5.5381,  -5.6212],\n",
      "         [-10.8537, -10.4793,  -2.7143,  ...,  10.4278,  -5.5381,  -5.6212],\n",
      "         [ -0.3336,  24.7253,   6.5446,  ...,  22.0388,   0.3988,  14.1006],\n",
      "         [ 42.4858, -16.3742,  40.3683,  ...,   0.0000, -28.2959,  -4.9783]]],\n",
      "       grad_fn=<MulBackward0>)\n",
      "torch.Size([2, 4, 512])\n"
     ]
    }
   ],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model,dropout,max_len=5000):\n",
    "        #dropout probablity set to 0\n",
    "        # max length of sentence no more than 5000 supposed\n",
    "        super(PositionalEncoding,self).__init__()\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        #position encoding martrix max_len* d_model\n",
    "        pe = torch.zeros(max_len,d_model)\n",
    "\n",
    "        #absolut pe\n",
    "        #arange(0,max_len): [maxlen]\n",
    "        #arange(0,max_len).unsqueeze(1):[maxlen*1]\n",
    "        position = torch.arange(0,max_len).unsqueeze(1)\n",
    "\n",
    "        #div_term diver matrix\n",
    "        div_term = torch.exp(torch.arange(0,d_model,2)*-(math.log(10000.0)))\n",
    "\n",
    "        pe[:,0::2]=torch.sin(position*div_term)\n",
    "        pe[:,1::2]=torch.cos(position*div_term)\n",
    "\n",
    "        #2d->3d\n",
    "        pe =pe.unsqueeze(0)\n",
    "        #rigister as buffer.Is not super parameters.Wont upgrade\n",
    "\n",
    "        self.register_buffer('pe',pe)\n",
    "\n",
    "    def forward(self,x):\n",
    "            #x;seq2vec\n",
    "            #maxlen is too long shorten to lenth of x\n",
    "            x = x + Variable(self.pe[:,:x.size(1)],requires_grad=False)\n",
    "            return self.dropout(x)\n",
    "        \n",
    "\n",
    "d_model = 512\n",
    "dropout = 0.1\n",
    "max_len = 60\n",
    "x = emb_rslt\n",
    "pe = PositionalEncoding(d_model,dropout,max_len)\n",
    "pe_result = pe(x)\n",
    "print(pe_result)\n",
    "print(pe_result.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-2.5505e-01, -1.0910e+00, -1.1701e-01, -1.6812e+00, -6.8660e-01],\n",
      "        [-5.8749e-01,  9.7613e-01,  2.2157e-01, -3.0746e-01, -1.8241e-01],\n",
      "        [-7.2120e-01,  3.8040e-02, -1.7941e+00, -1.1828e-03,  2.4766e-02],\n",
      "        [ 1.8616e+00, -1.5868e+00, -1.3467e+00,  5.3304e-01,  1.4029e+00]])\n",
      "tensor([[-0.3188, -1.3638, -0.0000, -0.0000, -0.8582],\n",
      "        [-0.7344,  1.2202,  0.0000, -0.3843, -0.2280],\n",
      "        [-0.9015,  0.0475, -2.2427, -0.0000,  0.0310],\n",
      "        [ 0.0000, -1.9835, -0.0000,  0.6663,  1.7536]])\n"
     ]
    }
   ],
   "source": [
    "#nn.Dropout\n",
    "#drop nerve at percentage p\n",
    "# remain all /(1-p)\n",
    "m = nn.Dropout(0.2)\n",
    "input = torch.randn(4,5)\n",
    "print(input)\n",
    "output = m(input)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 3, 4]])\n",
      "tensor([[1],\n",
      "        [2],\n",
      "        [3],\n",
      "        [4]])\n",
      "torch.Size([4])\n",
      "torch.Size([4, 1])\n"
     ]
    }
   ],
   "source": [
    "#torch.unsqueeze\n",
    "#add a dimension at position n\n",
    "x = torch.tensor([1,2,3,4])\n",
    "print(torch.unsqueeze(x,0))\n",
    "print(torch.unsqueeze(x,1))\n",
    "print(x.shape)\n",
    "print(x.unsqueeze(1).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pe tensor([[0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.]])\n",
      "abs p tensor([0, 1, 2, 3])\n",
      "abs p unsqueeze tensor([[0],\n",
      "        [1],\n",
      "        [2],\n",
      "        [3]])\n",
      "div_mid tensor([0])\n",
      "dt tensor([1.])\n",
      "abs p*dt tensor([[0.],\n",
      "        [1.],\n",
      "        [2.],\n",
      "        [3.]])\n",
      "size torch.Size([4, 1])\n",
      "pe tensor([[ 0.0000,  1.0000],\n",
      "        [ 0.8415,  0.5403],\n",
      "        [ 0.9093, -0.4161],\n",
      "        [ 0.1411, -0.9900]])\n",
      "pe unsqueeze tensor([[[ 0.0000,  1.0000],\n",
      "         [ 0.8415,  0.5403],\n",
      "         [ 0.9093, -0.4161],\n",
      "         [ 0.1411, -0.9900]]])\n",
      "input size: torch.Size([1, 4, 2])\n",
      "output: tensor([[[13.0000,  3.0000],\n",
      "         [13.8415,  2.5403],\n",
      "         [13.9093,  1.5839],\n",
      "         [13.1411,  1.0100]]])\n"
     ]
    }
   ],
   "source": [
    "#demo @ml=4 dm =2\n",
    "a = torch.zeros(4,2)\n",
    "print(\"pe\",a)\n",
    "b = torch.arange(0,4)\n",
    "print(\"abs p\",b)\n",
    "b = b.unsqueeze(1)\n",
    "print(\"abs p unsqueeze\",b)\n",
    "div_mid = torch.arange(0,2,2)#0,d_model,2\n",
    "print(\"div_mid\",div_mid)\n",
    "div_t =torch.exp(div_mid*-(math.log(10000.0)/d_model))\n",
    "print(\"dt\",div_t)\n",
    "print(\"abs p*dt\",b*div_t)\n",
    "# abs p:[4,1]\n",
    "# dt :[1,1]\n",
    "# broadcasting:[4,1]\n",
    "print(\"size\",a[:,0::2].shape)#[4,1]\n",
    "a[:,0::2]=torch.sin(b*div_t)\n",
    "a[:,1::2]=torch.cos(b*div_t)\n",
    "print(\"pe\",a)\n",
    "a=a.unsqueeze(0)\n",
    "print(\"pe unsqueeze\",a)\n",
    "\n",
    "\n",
    "input = torch.LongTensor([[[13,2],[13,2], [13,2], [13,2]]]) \n",
    "\n",
    "print(\"input size:\", input.size())  # (3,4,1)\n",
    "\n",
    "output = input.float() + a[:, :input.size(1)]\n",
    "print(\"output:\", output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
